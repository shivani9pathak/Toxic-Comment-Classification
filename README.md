# Toxic-Comment-Classification
This project implements a multi-label text classification model to detect different types of toxic comments such as:  Toxic  Severe Toxic  Obscene  Threat  Insult  Identity Hate  It is built using the Jigsaw Toxic Comment Classification Challenge dataset and applies NLP techniques for data cleaning, feature extraction, and classification
